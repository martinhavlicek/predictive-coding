# Classification experiments

This folder contains classification models that are trained on learned representations generated by PredNet and other pre-trained models.

## Action recognition with small datasets
Objectives:
* Investigate the limitations of Convnet representations on video understanding tasks
* Test the influence of the amount of unsupervised training data on the supervised task performance

#### Test set

| Model      | Easy (test acc) | Hard (test acc) |
| -------------                  | :--:  | :--:  |
| VGG ImageNet                   | 0.884 | 0.463 |
| PredNet random                 | 0.521 | 0.505 |
| PredNet KITTI                  | 0.700 | 0.511 |
| PredNet KITTI + Moments 1h     | 0.705 | 0.589 |
| PredNet KITTI + Moments 1.25h* | 0.716 | 0.589 |
| PredNet KITTI + Moments 3.33h  | 0.658 | 0.621 |
| PredNet KITTI + Moments 66.6h  | _now running_ |

#### Validation set

| Model    | Easy (loss) | Hard (loss) | Easy (acc) | Hard (acc) |    
| -------------                  | :---: | :---: | :---: | :---: |
| VGG ImageNet                   | 0.274 | 0.688 | 0.867 | 0.578 |
| PredNet random                 | 0.690 | 0.694 | 0.544 | 0.556 |
| PredNet KITTI                  | 0.582 | 0.685 | 0.722 | 0.622 |
| PredNet KITTI + Moments 1h     | 0.470 | 0.649 | 0.778 | 0.611 |
| PredNet KITTI + Moments 1.25h* | 0.513 | 0.668 | 0.768 | 0.595 |
| PredNet KITTI + Moments 3.33h  | 0.583 | 0.676 | 0.778 | 0.500 |

\* _In this run we let the model "see" the held-out data_

## Out-of-domain action recognition: UCF-101
Objectives:
* Assess the performance of model variants on an out-of-domain task
* Compare with baselines from the literature (focus on unsupervised approaches)

| Model                       | UCF-101 RGB (%) | Pre-training dataset | Pre-training size (frames) |
| -------------               | :---: | :---: |
| CNN tuple verification [1]  | 50.2 | UCF-101         | 2.7M  |
| Random LSTM [2]             | 74.5 | Sports-1M       | 0     |
| Composite LSTM [2]          | 75.8 | Sports-1M       | 32.4M |
| PredNet                     |      | Moments in Time | 2.4M  |
| PredNet finetuned           |      | Moments in Time | 2.4M  |

[1] Misra, I., Zitnick, C. L., & Hebert, M. (2016, October). [Shuffle and learn: unsupervised learning using temporal order verification](https://link.springer.com/chapter/10.1007/978-3-319-46448-0_32). In European Conference on Computer Vision (pp. 527-544). Springer, Cham.

[2] Srivastava, N., Mansimov, E., & Salakhudinov, R. (2015, June). [Unsupervised learning of video representations using lstms](https://arxiv.org/abs/1502.04681). In International conference on machine learning (pp. 843-852).


## Exploring the audio modality
Objectives:
* Check if our unsupervised learning approach can learn useful representations from audio
* Check if the audio modality provides complementary information 

## Models


### Convolutional LSTM (PredNet features)
```
Layer (type)                 Output Shape              Param #   
=================================================================
conv_lst_m2d_1 (ConvLSTM2D)  (None, 5, 16, 20, 10)     72760     
_________________________________________________________________
conv3d_1 (Conv3D)            (None, 5, 16, 20, 1)      271       
_________________________________________________________________
flatten_1 (Flatten)          (None, 1600)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 32)                51232     
_________________________________________________________________
activation_1 (Activation)    (None, 32)                0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 66        
_________________________________________________________________
activation_2 (Activation)    (None, 2)                 0         
=================================================================
Total params: 124,329
Trainable params: 124,329
Non-trainable params: 0
```

### Convolutional LSTM (VGG features)

```
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv_lst_m2d_1 (ConvLSTM2D)  (None, 30, 5, 5, 10)      187960    
_________________________________________________________________
conv3d_1 (Conv3D)            (None, 30, 5, 5, 1)       271       
_________________________________________________________________
flatten_1 (Flatten)          (None, 750)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 32)                24032     
_________________________________________________________________
activation_1 (Activation)    (None, 32)                0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 66        
_________________________________________________________________
activation_2 (Activation)    (None, 2)                 0         
=================================================================
Total params: 212,329
Trainable params: 212,329
Non-trainable params: 0
```
